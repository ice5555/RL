{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c50366e0",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b538f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806e18f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核无法启动，因为 Python 环境“torch-mps (Python -1.-1.-1)”不再可用。请考虑选择另一个内核或刷新 Python 环境列表。"
     ]
    }
   ],
   "source": [
    "!pip install -q --no-deps datasets sentence-transformers faiss-cpu rank_bm25 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ba8faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio, logging\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "import torch, random, faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "nest_asyncio.apply()\n",
    "logging.basicConfig(level = logging.INFO, format=\"%(asctime)s | %(levelname)s | %(message)s \", force=True)\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "BASE_DIR = Path(\"/content/drive/MyDrive/hotpot_qa\")\n",
    "BASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TOTAL_SAMPLE = 10000\n",
    "EVAL_RATIO = 0.2\n",
    "\n",
    "CORPUS_PATH   = BASE_DIR/\"corpus.parquet\"\n",
    "EVAL_PATH     = BASE_DIR/\"eval.parquet\"\n",
    "FAISS_TXT     = BASE_DIR/\"index_text_flatip.faiss\"\n",
    "FAISS_IMG     = BASE_DIR/\"index_img_flatip.faiss\"\n",
    "\n",
    "LORA_CKPT     = BASE_DIR/\"lora_sft_ckpt\"\n",
    "DPO_CKPT      = BASE_DIR/\"dpo_finetuned_ckpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21120a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b6711",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m内核无法启动，因为 Python 环境“torch-mps (Python -1.-1.-1)”不再可用。请考虑选择另一个内核或刷新 Python 环境列表。"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd, re, itertools\n",
    "\n",
    "hp_raw = load_dataset('hotpot_qa', 'fullwiki', split='validation[:200]')\n",
    "\n",
    "docs = []\n",
    "for ex in hp_raw:\n",
    "    for title, sents in ex['context']:\n",
    "        docs.append({\n",
    "            'title': title,\n",
    "            'text': ' '.join(sents).strip()\n",
    "        })\n",
    "docs_df = pd.DataFrame(docs).drop_duplicates('title').reset_index(drop=True)\n",
    "docs_df['row_id'] = docs_df.index\n",
    "docs_df.to_parquet(CORPUS_PATH, index=False)\n",
    "print('Corpus saved: ', CORPUS_PATH, '| size=', len(docs_df))\n",
    "# 把所有 (title, 文本段落) 展平成一个 DataFrame，去重后存为 corpus.parquet。\n",
    "# 同理把 question/answer/gold_docs/keywords 做成 eval.parquet。\n",
    "title2id = {\n",
    "    row.title: int(row.row_id) for row in docs_df.itertuples()\n",
    "}\n",
    "\n",
    "def gold_ids(supp):\n",
    "    return sorted({title2id[t] for t, _ in supp if t in title2id})\n",
    "\n",
    "def keywords(ans):\n",
    "    toks = re.findall(r'\\w+', ans.lower())\n",
    "    return list(dict.fromkeys([t for t in toks if len(t)>2]))[:5]\n",
    "\n",
    "eval_rows = []\n",
    "for ex in hp_raw:\n",
    "    eval_rows.append({\n",
    "        'row_id': len(eval_rows),\n",
    "        'question': ex['question'],\n",
    "        'answer': ex['answer'],\n",
    "        'gold_docs': gold_ids(ex['supporting_facts']),\n",
    "        'keywords': keywords(ex['question']),\n",
    "\n",
    "    })\n",
    "\n",
    "eval_df = pd.DataFrame(eval_rows)\n",
    "eval_df.to_parquet(EVAL_PATH, index=False)\n",
    "print(\"Eval saved:\", EVAL_PATH, \"| size =\", len(eval_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd6e447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import  SentenceTransformer\n",
    "\n",
    "embed_model='sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(embed_model, device=DEVICE)\n",
    "embeddings = model.encode(docs_df['text'].tolist(), show_progress_bar=True, convert_to_numpy=True, normalize_embeddings=True).astype('float32')\n",
    "\n",
    "index=faiss.IndexFlatIp(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "faiss.write_index(index, str(FAISS_TXT))\n",
    "print('FAISS saved: ', FAISS_TXT, '| vectors = ', index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfcbdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可选：加载回来看一下\n",
    "chk_index = faiss.read_index(str(FAISS_TXT))\n",
    "qv = model.encode([\"Albert Einstein\"], normalize_embeddings=True).astype(\"float32\")\n",
    "sims, ids = chk_index.search(qv.reshape(1,-1), 5)\n",
    "print(\"Top titles:\", docs_df.loc[ids[0], \"title\"].tolist())\n",
    "print(\"✅ Hotpot data ready — 以上三文件已生成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe632c8",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from tqdm import tqdm\n",
    "from rank_bm25 import BM25Okapi\n",
    "import re\n",
    "\n",
    "\n",
    "class Retriever(ABC):\n",
    "    @abstractmethod\n",
    "    def retrieve(self, query, top_k):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9850f2aa",
   "metadata": {},
   "source": [
    "## BM25Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e68e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Retriever(Retriever):\n",
    "    def __init__(self, corpus: pd.DataFrame, text_col=\"text\"):\n",
    "        self.corpus    = corpus\n",
    "        self.texts     = corpus[text_col].tolist()\n",
    "        # 1) tokenize once\n",
    "        self.tokenized = [re.findall(r'\\w+', txt.lower()) for txt in self.texts]\n",
    "        # 2) build BM25 model\n",
    "        self.bm25 = BM25Okapi(self.tokenized)\n",
    "        # 保存 row_id 列表，用于索引映射\n",
    "        self.row_ids = corpus.index.to_list()\n",
    "\n",
    "    def retrieve(self, query, top_k):\n",
    "        q_tok  = re.findall(r'\\w+', query.lower())\n",
    "        scores = self.bm25.get_scores(q_tok)             # numpy array\n",
    "        top_n  = np.argsort(scores)[::-1][:top_k]        # 文档内部下标\n",
    "        ids    = [self.row_ids[i] for i in top_n]        # 转回 row_id\n",
    "        return {\"ids\": ids, \"scores\": scores[top_n].tolist()}\n",
    "\n",
    "    def get_content(self, ids, field=\"text\"):\n",
    "        if isinstance(ids, int):\n",
    "            ids = [ids]\n",
    "        return [self.corpus.loc[i, field] for i in ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1f357",
   "metadata": {},
   "source": [
    "# CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61733c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoderReranker:\n",
    "    def __init__(self, model_name, device=\"cuda\"):\n",
    "        self.model = CrossEncoder(model_name, device=device)\n",
    "\n",
    "    def rerank(self, query: str, docs: list[str], row_ids: list[int], top_k: int):\n",
    "        # Debug\n",
    "        # print(f\"docs type: {type(docs)}, first: {docs[0] if docs else None}\")\n",
    "        # print(f\"row_ids: {row_ids[:5]}, total={len(row_ids)}\")\n",
    "        pairs = [[query, d] for d in docs]\n",
    "        scores = np.asarray(self.model.predict(pairs, batch_size=32)).flatten()\n",
    "        # print(f\"pairs: {len(pairs)}, scores: {len(scores)}\")\n",
    "        assert len(scores) == len(row_ids), \"Mismatch between scores and row_ids!\"\n",
    "        n = min(top_k, len(row_ids))\n",
    "        order = np.argsort(scores)[::-1][:n]\n",
    "        return [(row_ids[int(i)], float(scores[i])) for i in order]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993e829",
   "metadata": {},
   "source": [
    "# Query_Rewritter & PromptBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4eaeec",
   "metadata": {},
   "source": [
    "## Query_Rewritter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYNONYM_MAP = {\n",
    "    \"connect\": [\"plug\", \"attach\", \"link\"],\n",
    "    \"setup\": [\"configure\", \"install\"],\n",
    "    \"how\": [\"how to\", \"how do I\"],\n",
    "    \"price\": [\"cost\", \"charge\", \"fee\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4a1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "from transformers import pipeline\n",
    "\n",
    "class QueryRewriter:\n",
    "    \"\"\"\n",
    "    基于规则 + 小模型自动做同义/长尾扩展。\n",
    "    1) 规则层：关键词同义替换字典\n",
    "    2) LLM 层：对长尾 query 用 GPT-3.5 判断是否需要扩写\n",
    "    \"\"\"\n",
    "    def __init__(self, synonym_map= None, stopwords=None, device=0):\n",
    "        self.synmap = synonym_map or {\n",
    "            \"connect\": [\"plug\", \"attach\", \"link\"],\n",
    "            \"setup\": [\"configure\", \"install\"],\n",
    "            \"price\": [\"cost\", \"charge\", \"fee\"],\n",
    "            \"how\": [\"how to\", \"how do I\"],\n",
    "        }\n",
    "        self.expander = pipeline(\"text2text-generation\",\n",
    "                                 model=\"google/flan-t5-base\", device=device)\n",
    "        self.stopwords = stopwords or {\"setup\", \"login\", \"price\"}\n",
    "\n",
    "    def rewrite(self, query: str):\n",
    "        # 1. 规则扩展（只扩展一次，防止连锁递归）\n",
    "        rewrites = [query]\n",
    "        for k, vs in self.synmap.items():\n",
    "            # 只替换一次\n",
    "            pattern = rf\"\\b{k}\\b\"\n",
    "            if re.search(pattern, query, flags=re.IGNORECASE):\n",
    "                for v in vs:\n",
    "                    q_new = re.sub(pattern, f\"{k}/{v}\", query, flags=re.IGNORECASE, count=1)\n",
    "                    if q_new != query:\n",
    "                        rewrites.append(q_new)\n",
    "                break  # 只扩一个词，避免多个叠加\n",
    "\n",
    "        # 2. LLM扩写，如果很短才扩写\n",
    "        if len(query.split()) < 5:\n",
    "            prompt = f\"Please rewrite or expand this search query for better clarity and detail: {query}\"\n",
    "            out = self.expander(prompt, max_length=64, clean_up_tokenization_spaces=True)[0][\"generated_text\"]\n",
    "            rewrites.append(out.strip())\n",
    "\n",
    "        # 返回多条候选query，可供multi-query检索用\n",
    "        return list(dict.fromkeys(rewrites))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1f052",
   "metadata": {},
   "source": [
    "## PromptBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Optional\n",
    "\n",
    "class PromptBuilder:\n",
    "    \"\"\"\n",
    "    三层可插拔 Prompt 架构：\n",
    "      1) system_prompt：系统角色和风格指令\n",
    "      2) few_shot：N条示例问答\n",
    "      3) context：检索到的上下文片段\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_prompt: str = \"You are a helpful Amazon QA assistant.\",\n",
    "        few_shot: Optional[List[Dict[str, str]]] = None,\n",
    "        max_context: int = 3\n",
    "    ):\n",
    "        self.system = system_prompt\n",
    "        self.few_shot = few_shot or []\n",
    "        self.max_ctx = max_context\n",
    "\n",
    "    def build(\n",
    "        self,\n",
    "        query: str,\n",
    "        contexts: List[str],\n",
    "        image_tags: Optional[List[str]] = None\n",
    "    ) -> str:\n",
    "        parts = []\n",
    "        # 1. System Prompt\n",
    "        parts.append(f\"SYSTEM:\\n{self.system}\\n\")\n",
    "        # 2. Few-Shot 示例\n",
    "        if self.few_shot:\n",
    "            for ex in self.few_shot:\n",
    "                parts.append(f\"EXAMPLE:\\nQ: {ex['q']}\\nA: {ex['a']}\\n\")\n",
    "        # 3. 用户问题\n",
    "        parts.append(f\"USER QUERY:\\n{query}\\n\")\n",
    "        # 4. 检索上下文（文本/图片）\n",
    "        for i, ctx in enumerate(contexts[:self.max_ctx]):\n",
    "            if image_tags and i < len(image_tags):\n",
    "                parts.append(f\"CONTEXT {i+1} [Image: {image_tags[i]}]:\\n{ctx}\\n\")\n",
    "            else:\n",
    "                parts.append(f\"CONTEXT {i+1}:\\n{ctx}\\n\")\n",
    "        # 5. 指令收尾\n",
    "        parts.append(\"PLEASE ANSWER BASED ON ABOVE.\")\n",
    "        return \"\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad985c",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "class Generator(ABC):\n",
    "    @abstractmethod\n",
    "    def generate(self, prompt):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(Generator):\n",
    "    def __init__(self, model_id=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\", device=\"cuda\",\n",
    "                     batch_size=128, torch_dtype=torch.float16, max_new_tokens=128, temperature=0.2, do_sample=False):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_id,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            # device_map=\"auto\",\n",
    "            device_map=None,\n",
    "            trust_remote_code=True,\n",
    "            torch_dtype=torch_dtype\n",
    "        ).to(device)\n",
    "\n",
    "        self.pipe = pipeline(\n",
    "            \"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            # do_sample=do_sample,\n",
    "            # temperature=temperature,\n",
    "            num_return_sequences=1,\n",
    "            device=0 if device.startswith(\"cuda\") else -1,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        outs = self.pipe(prompt)\n",
    "\n",
    "        def clean(raw):\n",
    "            txt = raw.get(\"generated_text\", raw.get(\"text\", \"\"))\n",
    "            if \"Answer:\" in txt:\n",
    "                return txt.split(\"Answer:\")[-1].strip()\n",
    "            return txt.strip()\n",
    "\n",
    "        if isinstance(prompt, str):\n",
    "            return clean(outs[0])\n",
    "\n",
    "        results = []\n",
    "        for item in outs:\n",
    "            raw = item[0] if isinstance(item, list) else item\n",
    "            results.append(clean(raw))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5ab1d",
   "metadata": {},
   "source": [
    "# QASystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c4722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QASystem:\n",
    "    \"\"\"\n",
    "    Three-stage pipeline\n",
    "      1. retrieve_k  : 初筛候选数（交给 Retriever）        –– default 200\n",
    "      2. rerank_k    : 精排后保留数（交给 Reranker）       –– default 20\n",
    "      3. final_k     : 取前 k 条生成或返回（answer_top_k） –– default 5\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        retriever: Retriever,\n",
    "        text_gen= None,\n",
    "        reranker= None,\n",
    "        vis_gen=None,\n",
    "        classifier=None,\n",
    "        query_rewriter=None,\n",
    "        prompt_builder=None,\n",
    "        retrieve_k: int = 200,\n",
    "        rerank_k: int = 20,\n",
    "        answer_top_k: int = 5,\n",
    "    ):\n",
    "        self.retriever   = retriever\n",
    "        self.reranker    = reranker\n",
    "        self.text_gen    = text_gen\n",
    "        self.vis_gen     = vis_gen\n",
    "        self.classifier  = classifier\n",
    "        self.query_rewriter = query_rewriter\n",
    "        self.retrieve_k  = retrieve_k\n",
    "        self.rerank_k    = rerank_k\n",
    "        self.prompt_builder = prompt_builder\n",
    "        self.answer_k    = answer_top_k\n",
    "\n",
    "        self.last_cand_ids: list[int] = []\n",
    "\n",
    "    # ---------- public ----------\n",
    "    def answer(self, query: str | list[str], generate: bool = True):\n",
    "        if isinstance(query, list):\n",
    "            return [self._answer_single(q, generate) for q in query]\n",
    "        return self._answer_single(query, generate)\n",
    "\n",
    "    # ---------- private ----------\n",
    "    def _answer_single(self, query: str, generate: bool):\n",
    "        # ===  Query Rewrite（支持多路扩展） ===\n",
    "        if self.query_rewriter is not None:\n",
    "            rewrites = self.query_rewriter.rewrite(query)\n",
    "            if isinstance(rewrites, str):\n",
    "                rewrites = [rewrites]\n",
    "        else:\n",
    "            rewrites = [query]\n",
    "\n",
    "        # 1) 检索 retrieve_k\n",
    "        # === 2) 检索（多路查询合并 top-N） ===\n",
    "        all_cand_ids = []\n",
    "        for q in rewrites:\n",
    "            cand = self.retriever.retrieve(q, self.retrieve_k)\n",
    "            all_cand_ids.extend(cand[\"ids\"])\n",
    "        # 去重 & 保持顺序\n",
    "        seen = set()\n",
    "        all_cand_ids = [x for x in all_cand_ids if not (x in seen or seen.add(x))]\n",
    "        cand_ids = all_cand_ids[:self.retrieve_k]\n",
    "        self.last_cand_ids = cand_ids\n",
    "\n",
    "        # 2) 可选精排\n",
    "        if self.reranker:\n",
    "            docs = self.retriever.get_content(cand_ids, field=\"text\")\n",
    "            top_pairs = self.reranker.rerank(\n",
    "                query, docs, cand_ids, self.rerank_k\n",
    "            )\n",
    "            row_ids = [rid for rid, _ in top_pairs][: self.answer_k]\n",
    "        else:\n",
    "            row_ids = cand_ids[: self.answer_k]\n",
    "\n",
    "        # 3) 只想评检索就直接返回 ids\n",
    "        if not generate or self.text_gen is None:\n",
    "            return row_ids\n",
    "\n",
    "        # 4) 构造 prompt + 生成\n",
    "        contexts = self.retriever.get_content(row_ids, \"text\")\n",
    "        image_tags = None\n",
    "        # 如果你支持多模态，可以从 get_content(row_ids, \"img\") 里取 image_tags（如文件名或 URL）\n",
    "\n",
    "        if self.prompt_builder is not None:\n",
    "            prompt = self.prompt_builder.build(query, contexts, image_tags)\n",
    "        else:\n",
    "            # 兼容老 prompt\n",
    "            ctx = contexts[0]\n",
    "            prompt = f\"Question: {query}\\nContext: {ctx}\\nAnswer:\"\n",
    "\n",
    "        if (\n",
    "            self.classifier\n",
    "            and self.classifier.is_visual(query)\n",
    "            and self.vis_gen\n",
    "            and (img_path := self.retriever.get_content(row_ids[0], \"img\")[0])\n",
    "        ):\n",
    "            return self.vis_gen.generate(prompt, img_path)\n",
    "        return self.text_gen.generate(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849723d",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5261dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只需要这两个\n",
    "from your_module import TextGenerator, QASystem, BM25Retriever\n",
    "\n",
    "# 1) 实例化检索器（假设已加载 docs_df）\n",
    "bm25 = BM25Retriever(corpus=docs_df, text_col=\"text\")\n",
    "\n",
    "# 2) 实例化生成器——如想跑得更快，可以先换成 t5-small\n",
    "text_gen = TextGenerator(\n",
    "    model_id=\"t5-small\",    # 或者 \"gpt2\" 之类的小模型\n",
    "    device=\"cpu\"            # 或 \"cuda\"\n",
    ")\n",
    "\n",
    "# 3) 构建 QASystem，不传 classifier、vision_gen、rewriter\n",
    "qa = QASystem(\n",
    "    retriever=bm25,\n",
    "    text_gen=text_gen,\n",
    "    reranker=None,\n",
    "    prompt_builder=None,    # 先用内置默认 Prompt\n",
    "    retrieve_k=10,\n",
    "    rerank_k=5,\n",
    "    answer_top_k=3\n",
    ")\n",
    "\n",
    "# 4) 测试一次端到端\n",
    "print( qa.answer(\"Who wrote Pride and Prejudice?\", generate=True) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c23f0f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ea6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 放在 Notebook 某个 cell 里，确保 `!pip install evaluate` 已经装好\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, qa_system, eval_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        qa_system: 已实例化的 QASystem\n",
    "        eval_df: 包含 'question','answer','gold_docs' 列的 DataFrame\n",
    "        \"\"\"\n",
    "        self.qa = qa_system\n",
    "        self.df = eval_df.reset_index(drop=True)\n",
    "\n",
    "        # 加载评测器\n",
    "        self.metric_em    = evaluate.load(\"exact_match\")\n",
    "        self.metric_f1    = evaluate.load(\"f1\")\n",
    "        self.metric_bleu  = evaluate.load(\"bleu\")\n",
    "        self.metric_rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "    def eval_retrieval(self, ks=(5,10,20)):\n",
    "        \"\"\"返回 Recall@k 的 dict\"\"\"\n",
    "        results = {}\n",
    "        for k in ks:\n",
    "            hits = 0\n",
    "            for q, gold in zip(self.df[\"question\"], self.df[\"gold_docs\"]):\n",
    "                pred = self.qa.answer(q, generate=False)[:k]\n",
    "                if any(g in pred for g in gold):\n",
    "                    hits += 1\n",
    "            results[f\"Recall@{k}\"] = hits / len(self.df)\n",
    "        return results\n",
    "\n",
    "    def eval_generation(self):\n",
    "        \"\"\"\n",
    "        - 批量调用 .answer(generate=True)\n",
    "        - 最后一次性 compute 各指标\n",
    "        \"\"\"\n",
    "        preds, refs = [], []\n",
    "        for q, gold in tqdm(zip(self.df[\"question\"], self.df[\"answer\"]),\n",
    "                            total=len(self.df), desc=\"Gen Eval\"):\n",
    "            out = self.qa.answer(q, generate=True)\n",
    "            # 可能返回 list\n",
    "            if isinstance(out, (list, tuple)):\n",
    "                out = out[0]\n",
    "            preds.append(out.strip())\n",
    "            refs.append(gold.strip())\n",
    "\n",
    "        # EM / F1\n",
    "        em_res = self.metric_em.compute(predictions=preds, references=refs)\n",
    "        f1_res = self.metric_f1.compute(predictions=preds, references=refs)\n",
    "        # BLEU 要 list(list(tokens))\n",
    "        bleu_res = self.metric_bleu.compute(\n",
    "            predictions=[p.split() for p in preds],\n",
    "            references=[[r.split()] for r in refs]\n",
    "        )\n",
    "        rouge_res = self.metric_rouge.compute(predictions=preds, references=refs)\n",
    "\n",
    "        return {\n",
    "            \"EM\":    em_res[\"exact_match\"],\n",
    "            \"F1\":    f1_res[\"f1\"],\n",
    "            \"BLEU\":  bleu_res[\"bleu\"],\n",
    "            \"ROUGE\": rouge_res[\"rouge1\"]  # 你也可以看 rouge2、rougeL\n",
    "        }\n",
    "\n",
    "    def grid_search(self, param_grid: dict, metric=\"F1\"):\n",
    "        \"\"\"\n",
    "        简单的超参搜索\n",
    "        param_grid = {'retrieve_k':[50,100], 'rerank_k':[5,10]}\n",
    "        \"\"\"\n",
    "        from itertools import product\n",
    "        best = {\"score\": -1, \"params\": None}\n",
    "        for vals in product(*param_grid.values()):\n",
    "            params = dict(zip(param_grid.keys(), vals))\n",
    "            # 动态设置\n",
    "            for k, v in params.items():\n",
    "                setattr(self.qa, k, v)\n",
    "\n",
    "            # 只跑 Retrieval 或者 Generation 都行\n",
    "            gen_res = self.eval_generation()\n",
    "            score = gen_res.get(metric, 0)\n",
    "            print(f\"Params={params} → {metric}={score:.4f}\")\n",
    "\n",
    "            if score > best[\"score\"]:\n",
    "                best = {\"score\": score, \"params\": params.copy()}\n",
    "\n",
    "        print(\"Best:\", best)\n",
    "        return best\n",
    "\n",
    "    def ablation(self):\n",
    "        \"\"\"\n",
    "        示例：对比无 / 有 rewrite 和自定义 PromptBuilder 的效果\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        # baseline\n",
    "        results[\"baseline\"] = self.eval_generation()\n",
    "        # with rewrite\n",
    "        orig_rw = self.qa.query_rewriter\n",
    "        self.qa.query_rewriter = QueryRewriter()\n",
    "        results[\"with_rewrite\"] = self.eval_generation()\n",
    "        self.qa.query_rewriter = orig_rw\n",
    "        # with custom prompt\n",
    "        orig_pb = self.qa.prompt_builder\n",
    "        self.qa.prompt_builder = PromptBuilder(\n",
    "            system_prompt=\"You are an expert QA assistant.\",\n",
    "            few_shot=[{\"q\":\"Q1\",\"a\":\"A1\"}, {\"q\":\"Q2\",\"a\":\"A2\"}]\n",
    "        )\n",
    "        results[\"with_prompt\"] = self.eval_generation()\n",
    "        self.qa.prompt_builder = orig_pb\n",
    "\n",
    "        return pd.DataFrame(results).T\n",
    "\n",
    "# ===== 使用示例 =====\n",
    "# eval_df = pd.read_parquet(EVAL_PATH)\n",
    "# evaluator = Evaluator(qa, eval_df)\n",
    "# print(\"Retrieval:\", evaluator.eval_retrieval())\n",
    "# print(\"Generation:\", evaluator.eval_generation())\n",
    "# best = evaluator.grid_search({'retrieve_k':[50,100], 'rerank_k':[5,10]}, metric=\"F1\")\n",
    "# print(\"Ablation:\\n\", evaluator.ablation())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_env.py\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "class RAGEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    动作：离散   0~(N-1)  (e.g. top_k 档位 × temperature 档位 × rerank_on/off)\n",
    "    状态：连续向量 128 维 (可自行调整)\n",
    "    奖励：一次问答的 F1 / EM / (-loss) 等\n",
    "    \"\"\"\n",
    "    def __init__(self, qa_system, eval_df, topk_choices, temp_choices, rerank_choices):\n",
    "        super().__init__()\n",
    "        self.qa = qa_system\n",
    "        self.data = eval_df.to_dict(\"records\")          # list[dict]\n",
    "        self.ptr = 0                                    # 当前样本指针\n",
    "\n",
    "        # === 动作空间离散化 ===\n",
    "        self.topk_choices  = topk_choices      # e.g. [10,20,50]\n",
    "        self.temp_choices  = temp_choices      # e.g. [0.7,1.0,1.3]\n",
    "        self.rerank_choices= rerank_choices    # e.g. [0,1] (off/on)\n",
    "\n",
    "        self.actions = [(tk,tp,rr)\n",
    "                        for tk in topk_choices\n",
    "                        for tp in temp_choices\n",
    "                        for rr in rerank_choices]\n",
    "        self.action_space = spaces.Discrete(len(self.actions))\n",
    "\n",
    "        # === 状态空间（可先用占位向量） ===\n",
    "        self.observation_space = spaces.Box(-np.inf, np.inf, (128,), dtype=np.float32)\n",
    "\n",
    "    def _get_state(self):\n",
    "        \"\"\"可用检索相似度均值、历史 reward、query 长度等拼成 128 维；先用零向量占位\"\"\"\n",
    "        return np.zeros(128, dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.ptr = np.random.randint(0, len(self.data))  # 每个 episode 随机抽样\n",
    "        return self._get_state()\n",
    "\n",
    "    def step(self, action_id):\n",
    "        query, answer = self.data[self.ptr][\"question\"], self.data[self.ptr][\"answer\"]\n",
    "        # 1) 解码动作\n",
    "        top_k, temp, rerank_on = self.actions[action_id]\n",
    "\n",
    "        # 2) 设置到 QA system\n",
    "        self.qa.retrieve_k = top_k\n",
    "        self.qa.text_gen.pipe.kwargs[\"temperature\"] = temp   # 修改生成温度\n",
    "        self.qa.reranker   = self.qa.reranker if rerank_on else None\n",
    "\n",
    "        # 3) 执行一次 QA\n",
    "        pred = self.qa.answer(query, generate=True)\n",
    "        if isinstance(pred, list):\n",
    "            pred = pred[0]\n",
    "\n",
    "        # 4) 计算 reward（这里用 EM；可换成 F1、综合分）\n",
    "        reward = 1.0 if pred.strip().lower() == answer.strip().lower() else 0.0\n",
    "\n",
    "        # 5) 环境终止：一次问答即结束\n",
    "        done  = True\n",
    "        info  = {\"pred\": pred, \"gold\": answer}\n",
    "        next_state = self._get_state()\n",
    "        return next_state, reward, done, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_rl.py\n",
    "from stable_baselines3 import PPO\n",
    "from rag_env import RAGEnv\n",
    "\n",
    "env = RAGEnv(\n",
    "    qa_system = qa,          # 你前面实例化好的 QASystem\n",
    "    eval_df   = eval_df,     # 评估集 DataFrame\n",
    "    topk_choices  = [10,20,50],\n",
    "    temp_choices  = [0.7,1.0,1.3],\n",
    "    rerank_choices= [0,1]\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate = 3e-4,\n",
    "    n_steps       = 1024,\n",
    "    batch_size    = 128,\n",
    "    gamma         = 0.95,\n",
    "    verbose       = 1\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps = 10_000)\n",
    "model.save(\"ppo_rag\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d192e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = RAGEnv(...)\n",
    "\n",
    "model = PPO.load(\"ppo_rag\", env=env)\n",
    "obs = env.reset()\n",
    "rewards = []\n",
    "for _ in range(len(eval_df)):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "\n",
    "print(\"平均 EM：\", np.mean(rewards))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
