# cli/train_rl.py
import os
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")  # 静音并行 tokenizer 警告

import yaml
import argparse
import random
from pathlib import Path
import numpy as np
import pandas as pd

from envs.rag_env import RAGEnv
from cli.qa_system import QASystem
from retrieval.bm25 import BM25Retriever
from models.generator import TextGenerator
from utils.prompt import PromptBuilder
from data.hotpot import prepare_hotpot_data
from trainer.rl_trainer import RLTrainer


def run_baseline(env: RAGEnv, mode: str, episodes: int, fixed=None, log_dir: Path | None = None):
    """
    Baseline rollout，不依赖 SB3。
    mode: 'fixed' | 'random'
    - fixed: 用固定动作 (top_k, temperature, rerank_on)
    - random: 每个 episode 随机动作
    """
    rng = random.Random(42)
    rewards, ems, f1s, lats = [], [], [], []
    actions = []

    # 解析固定动作
    if mode == "fixed":
        fixed = fixed or {"top_k": 20, "temperature": 0.7, "rerank_on": 0}
        triple = (fixed["top_k"], fixed["temperature"], fixed["rerank_on"])
        # 如果环境提供映射函数，用它；否则直接找 index
        if hasattr(env, "action_id_for"):
            try:
                fixed_id = env.action_id_for(*triple)
            except Exception:
                fixed_id = 0
        else:
            try:
                fixed_id = env.actions.index(triple)
            except Exception:
                fixed_id = 0
    
    for _ in range(episodes):
        # 每个 episode 走一次：reset -> step
        env.reset()
        if mode == "random":
            action_id = env.action_space.sample()
        else:
            action_id = fixed_id
    
        _, r, terminated, truncated, info = env.step(action_id)
        # 单步 episode，直接拿 info
        rewards.append(float(r))
        ems.append(float(info.get("em", 0.0)))
        f1s.append(float(info.get("f1", 0.0)))
        lats.append(float(info.get("latency_sec", 0.0)))
        actions.append(action_id)
    
    metrics = {
        "avg_reward": float(np.mean(rewards)) if rewards else 0.0,
        "avg_em": float(np.mean(ems)) if ems else 0.0,
        "avg_f1": float(np.mean(f1s)) if f1s else 0.0,
        "avg_latency": float(np.mean(lats)) if lats else 0.0,
        "episodes": int(episodes),
        "mode": mode,
    }
    if mode == "fixed":
        metrics["fixed_action"] = str(triple)
    
    # 可选：写个简易 baseline 日志
    if log_dir is not None:
        log_dir.mkdir(parents=True, exist_ok=True)
        (log_dir / f"eval_baseline_{mode}.txt").write_text(str(metrics), encoding="utf-8")
    
    print(f"[Baseline-{mode}] {metrics}")
    return metrics


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", type=str, required=True)
    ap.add_argument("--baseline_only", action="store_true", help="只跑 baseline，不训练 PPO")
    ap.add_argument("--baseline_mode", choices=["fixed", "random"], default=None,
                    help="覆盖配置里的 baseline.mode")
    ap.add_argument("--episodes", type=int, default=None,
                    help="覆盖 baseline 评测轮数")
    args = ap.parse_args()

    log_dir = Path(".cache/rl_logs")
    
    with open(args.config) as f:
        cfg = yaml.safe_load(f)
    
    # 1) 数据准备（parquet）
    corpus_p, eval_p = prepare_hotpot_data(
        cfg["paths"]["dataset_json"],
        cfg["data"]["cache_dir"],
        sample=cfg["data"]["sample"]
    )
    df_c = pd.read_parquet(corpus_p)
    df_e = pd.read_parquet(eval_p)
    
    # 2) 组装 QA 系统
    retriever = BM25Retriever(df_c)
    generator = TextGenerator(
        model_id=cfg["model"]["name"],
        device=cfg["model"]["device"],
        max_new_tokens=cfg["model"]["max_new_tokens"],
    )
    qa_system = QASystem(retriever, generator, PromptBuilder())
    
    # 3) 环境
    env = RAGEnv(qa_system, df_e)
    
    # 4) Baseline 对照
    bl_cfg = cfg.get("baseline", {
        "mode": "fixed",
        "episodes": min(50, len(df_e)),
        "fixed": {"top_k": 20, "temperature": 0.7, "rerank_on": 0},
    })
    if args.baseline_mode is not None:
        bl_cfg["mode"] = args.baseline_mode
    if args.episodes is not None:
        bl_cfg["episodes"] = args.episodes
    
    if bl_cfg["mode"] in ("fixed", "random"):
        print(f"[Baseline] mode={bl_cfg['mode']} episodes={bl_cfg['episodes']}")
        run_baseline(env, bl_cfg["mode"], bl_cfg["episodes"], fixed=bl_cfg.get("fixed"), log_dir=log_dir)
    
    if args.baseline_only:
        return
    
    # 5) PPO 训练
    ppo_kwargs = cfg.get("ppo", {})
    trainer = RLTrainer(
        env,
        log_dir=str(log_dir),
        total_timesteps=cfg["train"]["total_timesteps"],
        ppo_kwargs=ppo_kwargs
    )
    print(f"[Info] Starting PPO with n_steps={ppo_kwargs.get('n_steps', 2048)} "
          f"batch_size={ppo_kwargs.get('batch_size', 64)}")
    trainer.train()
    
    # 6) 评估
    metrics3 = trainer.evaluate(n_episodes=3)
    print("Eval(3eps):", metrics3)
    metrics_full = trainer.evaluate(n_episodes=min(50, len(df_e)))
    print("Eval(full):", metrics_full)
    print(f"[Logs] CSV written to: {log_dir / 'train_log.csv'}")

if __name__ == "__main__":
    main()

from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import ast

LOG_DIR = Path(".cache/rl_logs")
TRAIN_CSV = LOG_DIR / "train_log.csv"
BL_FIXED  = LOG_DIR / "eval_baseline_fixed.txt"
BL_RANDOM = LOG_DIR / "eval_baseline_random.txt"

def load_baseline(p: Path):
    if p.exists():
        try:
            return ast.literal_eval(p.read_text())
        except Exception:
            return None
    return None

def add_baseline_lines(metric_name, fixed, random_):
    if fixed and f"avg_{metric_name}" in fixed:
        plt.axhline(fixed[f"avg_{metric_name}"], linestyle="--", label=f"fixed avg {metric_name}")
    if random_ and f"avg_{metric_name}" in random_:
        plt.axhline(random_[f"avg_{metric_name}"], linestyle=":", label=f"random avg {metric_name}")

def plot_metric(df, col, title, ylabel, out_path, window=20, with_baseline=True, fixed=None, random_=None):
    plt.figure()
    # 原始 per-episode
    df[col].plot(alpha=0.3, label=col)
    # 滚动平均（更平滑）
    if len(df) >= window:
        df[col].rolling(window).mean().plot(label=f"{col} (rolling {window})")
    # 基线
    if with_baseline:
        add_baseline_lines(col if col in ("reward","em","f1") else "reward", fixed, random_)
    plt.title(title)
    plt.xlabel("Episode")
    plt.ylabel(ylabel)
    plt.legend()
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()

def main():
    assert TRAIN_CSV.exists(), f"train log not found: {TRAIN_CSV}"
    df = pd.read_csv(TRAIN_CSV)
    fixed  = load_baseline(BL_FIXED)
    random_ = load_baseline(BL_RANDOM)

    outdir = Path("figs"); outdir.mkdir(parents=True, exist_ok=True)
    
    plot_metric(df, "reward",      "Episode Reward (with baselines)", "Reward",       outdir / "reward_with_baseline.png", fixed=fixed, random_=random_)
    plot_metric(df, "em",          "Exact Match (EM)",                "EM",           outdir / "em_with_baseline.png",     fixed=fixed, random_=random_)
    plot_metric(df, "f1",          "F1 Score",                        "F1",           outdir / "f1_with_baseline.png",     fixed=fixed, random_=random_)
    plot_metric(df, "latency_sec", "Latency per Episode (s)",         "Latency (s)",  outdir / "latency.png",              with_baseline=False)
    
    # 动作分布照旧
    plt.figure()
    df["top_k"].value_counts().sort_index().plot(kind="bar")
    plt.title("Action Distribution: top_k")
    plt.xlabel("top_k"); plt.ylabel("Count"); plt.tight_layout()
    plt.savefig(outdir / "topk_hist.png", dpi=150); plt.close()
    
    plt.figure()
    df["temperature"].value_counts().sort_index().plot(kind="bar")
    plt.title("Action Distribution: temperature")
    plt.xlabel("temperature"); plt.ylabel("Count"); plt.tight_layout()
    plt.savefig(outdir / "temp_hist.png", dpi=150); plt.close()
    
    print(f"[ok] saved to {outdir.resolve()}")

if __name__ == "__main__":
    main()

from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import ast

LOG_DIR = Path(".cache/rl_logs")
TRAIN_CSV = LOG_DIR / "train_log.csv"
BL_FIXED  = LOG_DIR / "eval_baseline_fixed.txt"
BL_RANDOM = LOG_DIR / "eval_baseline_random.txt"

def load_baseline(p: Path):
    if p.exists():
        try:
            return ast.literal_eval(p.read_text())
        except Exception:
            return None
    return None

def add_baseline_lines(metric_name, fixed, random_):
    if fixed and f"avg_{metric_name}" in fixed:
        plt.axhline(fixed[f"avg_{metric_name}"], linestyle="--", label=f"fixed avg {metric_name}")
    if random_ and f"avg_{metric_name}" in random_:
        plt.axhline(random_[f"avg_{metric_name}"], linestyle=":", label=f"random avg {metric_name}")

def plot_metric(df, col, title, ylabel, out_path, window=20, with_baseline=True, fixed=None, random_=None):
    plt.figure()
    # 原始 per-episode
    df[col].plot(alpha=0.3, label=col)
    # 滚动平均（更平滑）
    if len(df) >= window:
        df[col].rolling(window).mean().plot(label=f"{col} (rolling {window})")
    # 基线
    if with_baseline:
        add_baseline_lines(col if col in ("reward","em","f1") else "reward", fixed, random_)
    plt.title(title)
    plt.xlabel("Episode")
    plt.ylabel(ylabel)
    plt.legend()
    plt.tight_layout()
    plt.savefig(out_path, dpi=150)
    plt.close()

def main():
    assert TRAIN_CSV.exists(), f"train log not found: {TRAIN_CSV}"
    df = pd.read_csv(TRAIN_CSV)
    fixed  = load_baseline(BL_FIXED)
    random_ = load_baseline(BL_RANDOM)

    outdir = Path("figs"); outdir.mkdir(parents=True, exist_ok=True)
    
    plot_metric(df, "reward",      "Episode Reward (with baselines)", "Reward",       outdir / "reward_with_baseline.png", fixed=fixed, random_=random_)
    plot_metric(df, "em",          "Exact Match (EM)",                "EM",           outdir / "em_with_baseline.png",     fixed=fixed, random_=random_)
    plot_metric(df, "f1",          "F1 Score",                        "F1",           outdir / "f1_with_baseline.png",     fixed=fixed, random_=random_)
    plot_metric(df, "latency_sec", "Latency per Episode (s)",         "Latency (s)",  outdir / "latency.png",              with_baseline=False)
    
    # 动作分布照旧
    plt.figure()
    df["top_k"].value_counts().sort_index().plot(kind="bar")
    plt.title("Action Distribution: top_k")
    plt.xlabel("top_k"); plt.ylabel("Count"); plt.tight_layout()
    plt.savefig(outdir / "topk_hist.png", dpi=150); plt.close()
    
    plt.figure()
    df["temperature"].value_counts().sort_index().plot(kind="bar")
    plt.title("Action Distribution: temperature")
    plt.xlabel("temperature"); plt.ylabel("Count"); plt.tight_layout()
    plt.savefig(outdir / "temp_hist.png", dpi=150); plt.close()
    
    print(f"[ok] saved to {outdir.resolve()}")

if __name__ == "__main__":
    main()



# 先让 CLI 写出 baseline 文件（fixed / random 任一即可）
python -m cli.train_rl --config config/hotpotqa_rl.yaml --baseline_only
# 然后画图
python scripts/plot_rl_with_baseline.py